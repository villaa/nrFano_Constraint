{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we may need some code in the ../python directory and/or matplotlib styles\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../python/')\n",
    "\n",
    "#set up matplotlib\n",
    "os.environ['MPLCONFIGDIR'] = '../mplstyles'\n",
    "print(os.environ['MPLCONFIGDIR'])\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "#got smarter about the mpl config: see mplstyles/ directory\n",
    "plt.style.use('standard')\n",
    "print(mpl.__version__) \n",
    "print(mpl.get_configdir())\n",
    "\n",
    "\n",
    "#fonts\n",
    "# Set the font dictionaries (for plot title and axis titles)\n",
    "title_font = {'fontname':'Arial', 'size':'16', 'color':'black', 'weight':'normal',\n",
    "              'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "axis_font = {'fontname':'Arial', 'size':'32'}\n",
    "legend_font = {'fontname':'Arial', 'size':'22'}\n",
    "\n",
    "#fonts global settings\n",
    "mpl.rc('font',family=legend_font['fontname'])\n",
    "\n",
    "\n",
    "#set up numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Fits have been done in notebooks `edelweiss_C.ipynb` and `Qwidth_confirm.ipynb` which give the functional forms of the \"C\" parameter as a function of energy and the correction to this parameter, called C$^{\\prime}$, due to multiple scattering. \n",
    "\n",
    "The fits in each case have constant components and a slope that are correlated, to find \"bounding curves\" of these functions given the statistical errors may be easiest with an MCMC fitting approach. That is discussed here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Scatters\n",
    "\n",
    "For the multiple scatters fitting that was first accomplieshed in the notebook `Qwidth_confirm.ipynb`, the goal would be to expand on the central value for each parameter of the fit, taking into account correlation. From the previous fit we have the following parameters from the `lmfit` output. \n",
    "\n",
    "\n",
    "Parameter name|Parameter value|Parameter uncertainty\n",
    ":-|:-|:-\n",
    "C$_{ms}$|0.0202 | 0.0014 (6.7%)\n",
    "m | 5.343$\\times$10$^{-5}$ | 1.513$\\times$10$^{-5}$ (28.3%)\n",
    "corr(C$_{ms}$,m) | -0.898 | - \n",
    "\n",
    "\n",
    "The slope parameter has high fractional uncertainty and the parameters are highly correlated. In this situation fluctuating each of them upward by the 1$\\sigma$ level and taking the resulting cuve from those parameters will overestimate the true uncertainty on the measured quadrature correction for multiple scatters, C$^{\\prime}$, as a function of energy. The _correlation_ parameter is a dimensionless parameter between -1 and 1 where the magnitude describes the size of the correlation and the sign describes whether it is an _anti_correlation (see [[corrNotes][corrNotes]])\n",
    "\n",
    "[corrNotes]: https://www.unige.ch/sciences/astro/files/5413/8971/4090/2_Segransan_StatClassUnige.pdf \"correlation notes\"\n",
    "\n",
    "We therefore seek a fitting method that will yield the two-dimensional distribution of C$_{ms}$ and m. The method we use is a Markov Chain Monte Carlo (MCMC) technique, as implemented by the `emcee` library [[emcee][emcee]]. \n",
    "\n",
    "[emcee]: https://emcee.readthedocs.io/en/v2.2.1/user/line/ \"emcee implemntation of MCMC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start, below, by getting a version of the high-statistics mulitple-scatter simulation, and the calculation for the single-scatter predicted yield width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "filename = 'data/sims.h5'\n",
    "#remove vars\n",
    "f = h5py.File(filename,'r')\n",
    "\n",
    "#save the results for the Edw fit\n",
    "path='{}/'.format('NR')\n",
    "\n",
    "xE = np.asarray(f[path+'xE'])\n",
    "qbootsigs_nr_ms = np.asarray(f[path+'qbootsigs'])\n",
    "qbootsigerrsu_nr_ms = np.asarray(f[path+'qbootsigerrsu'])\n",
    "qbootsigerrsl_nr_ms = np.asarray(f[path+'qbootsigerrsl'])\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the NR calculations for our yield band\n",
    "import fano_calc as fc\n",
    "Enr,signr = fc.RWCalc(filename='data/res_calc.h5',band='NR',alpha=(1/18.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make a callable out of the predicted single-scatter resolution\n",
    "import scipy.interpolate as inter\n",
    "\n",
    "sigQnr_c = inter.InterpolatedUnivariateSpline(Enr, signr, k=3)\n",
    "sigQnr_c_v = np.vectorize(sigQnr_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the model we have for the single-scatter yield width, $\\sigma_{\\mathrm{Q}ss}(E_r)$, and construct a model for the width including all scatters as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{\\mathrm{Q}} = \\sqrt{\\sigma_{\\mathrm{Q}ss}^2 + C^{\\prime2}},\n",
    "\\end{equation}\n",
    "\n",
    "Where C$^{\\prime}$ is modeled as the linear (in recoil energy) function C$_{ms}$ + m$E_r$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also construct a residual function for use with lmfit\n",
    "import lmfit as lmf\n",
    "\n",
    "def residual(params, x, data, eps_data,sigQfunc):\n",
    "    Cms = params['Cms']\n",
    "    m = params['m']\n",
    "\n",
    "\n",
    "    model = np.sqrt(sigQfunc(x)**2 + (Cms+m*x)**2)\n",
    "\n",
    "    return (data-model) / eps_data\n",
    "\n",
    "def residual_const(params, x, data, eps_data,sigQfunc):\n",
    "    Cms = params['Cms']\n",
    "\n",
    "\n",
    "    model = np.sqrt(sigQfunc(x)**2 + (Cms)**2)\n",
    "\n",
    "    return (data-model) / eps_data\n",
    "\n",
    "#do it with lmfit\n",
    "params = lmf.Parameters()\n",
    "params.add('Cms', value=0.02)\n",
    "lmfout = lmf.minimize(residual_const, params, args=(xE, qbootsigs_nr_ms, qbootsigerrsu_nr_ms,sigQnr_c_v))\n",
    "#print(lmf.fit_report(lmfout))\n",
    "print('lmfit result--multiples: constant C')\n",
    "print(lmf.report_fit(lmfout.params))\n",
    "\n",
    "Cms_const = lmfout.params['Cms'].value\n",
    "\n",
    "params = lmf.Parameters()\n",
    "params.add('Cms', value=0.02)\n",
    "params.add('m', value=0)\n",
    "lmfout = lmf.minimize(residual, params, args=(xE, qbootsigs_nr_ms, qbootsigerrsu_nr_ms,sigQnr_c_v))\n",
    "#print(lmf.fit_report(lmfout))\n",
    "print('lmfit result--multiples: linear C')\n",
    "print(lmf.report_fit(lmfout.params))\n",
    "\n",
    "Cms = lmfout.params['Cms'].value\n",
    "slope = lmfout.params['m'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(xE))\n",
    "print(xE)\n",
    "print(np.shape(qbootsigs_nr_ms))\n",
    "print(qbootsigs_nr_ms)\n",
    "\n",
    "#get rid of the firs point because it's spurious\n",
    "#xE = xE[2:]\n",
    "#qbootsigs_nr_ms = qbootsigs_nr_ms[2:]\n",
    "#qbootsigerrsu_nr_ms = qbootsigerrsu_nr_ms[2:]\n",
    "\n",
    "#print(np.shape(xE))\n",
    "#print(xE)\n",
    "#print(np.shape(qbootsigs_nr_ms))\n",
    "#print(qbootsigs_nr_ms)\n",
    "#print(np.shape(qbootsigerrsu_nr_ms))\n",
    "#print(qbootsigerrsu_nr_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here on basically following https://emcee.readthedocs.io/en/latest/tutorials/line/\n",
    "\n",
    "#ACTUALLY\n",
    "#that above link is for the bleeding edge 3.0 ish version, it is not easy to install and appears to be failing tests\n",
    "#so use the stable:\n",
    "#https://emcee.readthedocs.io/en/stable/user/line/#marginalization-uncertainty-estimation\n",
    "#note several interfaces have changed in the 3.0x version so stick to this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, x, y, yerr,sigfunc):\n",
    "    Cms, m = theta\n",
    "    model = np.sqrt(sigfunc(x)**2 + (Cms+m*x)**2)\n",
    "    #sigma2 = yerr**2 + model**2*np.exp(2*log_f)\n",
    "    sigma2 = yerr**2\n",
    "    return -0.5*np.sum((y-model)**2/sigma2 + np.log(sigma2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "np.random.seed(42)\n",
    "nll = lambda *args: -log_likelihood(*args)\n",
    "initial = np.array([0.0207, 4.73e-5]) + 0.001*np.random.randn(2)\n",
    "soln = minimize(nll, initial, args=(xE, qbootsigs_nr_ms, qbootsigerrsu_nr_ms,sigQnr_c_v))\n",
    "Cms_ml, m_ml = soln.x\n",
    "\n",
    "print(\"Maximum likelihood estimates:\")\n",
    "print(\"m = {0:.4f}\".format(Cms_ml))\n",
    "print(\"b = {0:.3e}\".format(m_ml))\n",
    "\n",
    "\n",
    "plt.errorbar(xE, qbootsigs_nr_ms, yerr=qbootsigerrsu_nr_ms, fmt=\".k\", capsize=0)\n",
    "#plt.plot(x0, m_true*x0+b_true, \"k\", alpha=0.3, lw=3, label=\"truth\")\n",
    "#plt.plot(x0, np.dot(np.vander(x0, 2), w), \"--k\", label=\"LS\")\n",
    "#plt.plot(x0, np.dot(np.vander(x0, 2), [m_ml, b_ml]), \":k\", label=\"ML\")\n",
    "#plt.legend(fontsize=14)\n",
    "plt.xlim(10, 200)\n",
    "plt.ylim(0,0.05)\n",
    "plt.xlabel(\"E\")\n",
    "plt.ylabel(\"$\\sigma$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    Cms, m = theta\n",
    "    if 0.00 < Cms < 0.04 and -1e-4 < m < 1e-4:\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probability(theta, x, y, yerr,sigfunc):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, yerr,sigfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "ndim, nwalkers = 2, 100\n",
    "pos = [soln.x + 1e-5*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, \\\n",
    "          args=(xE, qbootsigs_nr_ms, qbootsigerrsu_nr_ms,sigQnr_c_v))\n",
    "\n",
    "sampler.run_mcmc(pos, 500)\n",
    "\n",
    "#import emcee\n",
    "#print(emcee.__version__)\n",
    "#pos = soln.x + 1e-4*np.random.randn(32, 2)\n",
    "#nwalkers, ndim = pos.shape\n",
    "\n",
    "#sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, \\\n",
    "#          args=(xE, qbootsigs_nr_ms, qbootsigerrsu_nr_ms,sigQnr_c_v))\n",
    "#sampler.run_mcmc(pos, 5000, progress=True)\n",
    "#chain = sampler.run_mcmc(pos, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(10, 7), sharex=True)\n",
    "#samples = sampler.get_chain()\n",
    "samples = sampler.chain\n",
    "labels = [\"Cms\", \"m\"]\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(np.transpose(samples[:, :, i]), \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, np.shape(samples)[1])\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "print(np.shape(samples))\n",
    "samples = sampler.chain[:, 100:, :].reshape((-1, ndim))\n",
    "print(np.shape(samples))\n",
    "fig = corner.corner(samples, labels=[\"$Cms$\", \"$m$\"],\n",
    "                      truths=[Cms, slope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "#xl = np.array([10, 200])\n",
    "xl = np.linspace(10, 200, 500)\n",
    "#print(xl)\n",
    "for Cms_em, m_em in samples[np.random.randint(len(samples), size=100)]:\n",
    "    pl.plot(xl, np.sqrt(sigQnr_c_v(xl)**2+(Cms_em+m_em*xl)**2), color=\"k\", alpha=0.1)\n",
    "pl.plot(xl, np.sqrt(sigQnr_c_v(xl)**2+(Cms+slope*xl)**2), color=\"r\", lw=2, alpha=0.8)\n",
    "#pl.errorbar(x, y, yerr=yerr, fmt=\".k\")\n",
    "pl.xlim(10, 200)\n",
    "pl.ylim(0,0.05)\n",
    "pl.errorbar(xE, qbootsigs_nr_ms, yerr=qbootsigerrsu_nr_ms, fmt=\".k\", capsize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampsize=100\n",
    "evec = np.zeros((np.shape(xl)[0],sampsize))\n",
    "#print(samples[np.random.randint(len(samples), size=sampsize)])\n",
    "i=0\n",
    "for Cms_em, m_em in samples[np.random.randint(len(samples), size=sampsize)]:\n",
    "    v = np.sqrt(sigQnr_c_v(xl)**2+(Cms_em+m_em*xl)**2)\n",
    "    #print(np.std(v))\n",
    "    #print(np.mean(v))\n",
    "    cent = np.sqrt(sigQnr_c_v(xl)**2+(Cms+slope*xl)**2)\n",
    "    evec[:,i] = v\n",
    "    #print(i)\n",
    "    #print(np.mean(v)+np.std(v))\n",
    "    #print(np.mean(v)-np.std(v))\n",
    "    i=i+1\n",
    "   \n",
    "upvec = np.mean(evec,axis=1)+np.std(evec,axis=1)\n",
    "dnvec = np.mean(evec,axis=1)-np.std(evec,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(xl, np.sqrt(sigQnr_c_v(xl)**2+(Cms+slope*xl)**2), color=\"r\", lw=2, alpha=0.8)\n",
    "pl.plot(xl, upvec, color=\"r\",linestyle=\"--\", lw=2, alpha=0.8)\n",
    "pl.plot(xl, dnvec, color=\"r\",linestyle=\"--\", lw=2, alpha=0.8)\n",
    "#pl.errorbar(x, y, yerr=yerr, fmt=\".k\")\n",
    "pl.xlim(10, 200)\n",
    "pl.ylim(0,0.05)\n",
    "pl.errorbar(xE, qbootsigs_nr_ms, yerr=qbootsigerrsu_nr_ms, fmt=\".k\", capsize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "#save the results for the MS fit\n",
    "path='{}/{}/'.format('mcmc','multiples')\n",
    "\n",
    "filename = 'data/mcmc_fits.h5'\n",
    "\n",
    "#remove vars\n",
    "f = h5py.File(filename,'a')\n",
    "exCms = path+'Cms' in f\n",
    "exm = path+'m' in f\n",
    "exsamp = path+'samples' in f\n",
    "exsampsize = path+'sampsize' in f\n",
    "exEr = path+'Er' in f\n",
    "exCsig_u = path+'Csig_u' in f\n",
    "exCsig_l = path+'Csig_l' in f\n",
    "exSigss = path+'Sigss' in f\n",
    "\n",
    "if exCms:\n",
    "  del f[path+'Cms']\n",
    "if exm:\n",
    "  del f[path+'m']\n",
    "if exsamp:\n",
    "  del f[path+'samples']\n",
    "if exsampsize:\n",
    "  del f[path+'sampsize']\n",
    "if exEr:\n",
    "  del f[path+'Er']\n",
    "if exCsig_u:\n",
    "  del f[path+'Csig_u']\n",
    "if exCsig_l:\n",
    "  del f[path+'Csig_l']\n",
    "if exSigss:\n",
    "  del f[path+'Sigss']\n",
    "\n",
    "dset = f.create_dataset(path+'Cms',np.shape(Cms),dtype=np.dtype('float64').type)\n",
    "dset[...] = Cms\n",
    "dset = f.create_dataset(path+'m',np.shape(slope),dtype=np.dtype('float64').type)\n",
    "dset[...] = slope\n",
    "dset = f.create_dataset(path+'samples',np.shape(samples),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = samples\n",
    "dset = f.create_dataset(path+'sampsize',np.shape(sampsize),dtype=np.dtype('float64').type)\n",
    "dset[...] = sampsize\n",
    "dset = f.create_dataset(path+'Er',np.shape(xl),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\")\n",
    "dset[...] = xl\n",
    "dset = f.create_dataset(path+'Csig_u',np.shape(upvec),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = upvec\n",
    "dset = f.create_dataset(path+'Csig_l',np.shape(dnvec),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = dnvec\n",
    "dset = f.create_dataset(path+'Sigss',np.shape(xl),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = sigQnr_c_v(xl)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Yield Widening (EDELWEISS Fit)\n",
    "\n",
    "This procedure can also be done for the fit (originally in the notebook `edelweiss_C.ipynb`) that extracts the uncertainty and central value for the experimentally observed widening parameter, C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from Edelweiss\n",
    "import pandas as pds\n",
    "res_data = pds.read_csv(\"data/edelweiss_NRwidth_GGA3_data.txt\", skiprows=1, \\\n",
    "                       names=['E_recoil', 'sig_NR', 'E_recoil_err', 'sig_NR_err'], \\\n",
    "                       delim_whitespace=True)\n",
    "\n",
    "resER_data = pds.read_csv(\"data/edelweiss_ERwidth_GGA3_data.txt\", skiprows=1, \\\n",
    "                         names=['E_recoil', 'sig_ER', 'sig_ER_err'], \\\n",
    "                         delim_whitespace=True)\n",
    "\n",
    "resER_data = resER_data.sort_values(by='E_recoil')\n",
    "\n",
    "print (res_data.head(10))\n",
    "E_recoil = res_data[\"E_recoil\"]\n",
    "sig_NR = res_data[\"sig_NR\"]\n",
    "sig_NR_err = res_data['sig_NR_err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some of the fit points are known to be \"bad\" because of the presence of inelastic scattering\n",
    "#to fix that ignore the first two points\n",
    "\n",
    "#do it with lmfit\n",
    "params = lmf.Parameters()\n",
    "params.add('Cms', value=0.04)\n",
    "lmfout = lmf.minimize(residual_const, params, args=(E_recoil[2::], sig_NR[2::], sig_NR_err[2::],sigQnr_c_v))\n",
    "#print(lmf.fit_report(lmfout))\n",
    "print('lmfit result--multiples: constant C')\n",
    "print(lmf.report_fit(lmfout.params))\n",
    "\n",
    "Cms_const = lmfout.params['Cms'].value\n",
    "\n",
    "params = lmf.Parameters()\n",
    "params.add('Cms', value=0.04)\n",
    "params.add('m', value=0)\n",
    "lmfout = lmf.minimize(residual, params, args=(E_recoil[2::], sig_NR[2::], sig_NR_err[2::],sigQnr_c_v))\n",
    "#print(lmf.fit_report(lmfout))\n",
    "print('lmfit result--multiples: linear C')\n",
    "print(lmf.report_fit(lmfout.params))\n",
    "\n",
    "Cms = lmfout.params['Cms'].value\n",
    "slope = lmfout.params['m'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_log_prior(theta):\n",
    "    Cms, m = theta\n",
    "    if 0.02 < Cms < 0.05 and -1e-3 < m < 1e-3:\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_log_probability(theta, x, y, yerr,sigfunc):\n",
    "    lp = new_log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, yerr,sigfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers = 2, 100\n",
    "pos = [[Cms,slope] + 1e-5*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, new_log_probability, \\\n",
    "          args=(E_recoil[2::], sig_NR[2::], sig_NR_err[2::],sigQnr_c_v))\n",
    "\n",
    "sampler.run_mcmc(pos, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(10, 7), sharex=True)\n",
    "#samples = sampler.get_chain()\n",
    "samples = sampler.chain\n",
    "labels = [\"Cms\", \"m\"]\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(np.transpose(samples[:, :, i]), \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, np.shape(samples)[1])\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(samples))\n",
    "samples = sampler.chain[:, 100:, :].reshape((-1, ndim))\n",
    "print(np.shape(samples))\n",
    "fig = corner.corner(samples, labels=[\"$Cms$\", \"$m$\"],\n",
    "                      truths=[Cms, slope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = np.linspace(10, 200, 500)\n",
    "#print(xl)\n",
    "for Cms_em, m_em in samples[np.random.randint(len(samples), size=100)]:\n",
    "    pl.plot(xl, np.sqrt(sigQnr_c_v(xl)**2+(Cms_em+m_em*xl)**2), color=\"k\", alpha=0.1)\n",
    "pl.plot(xl, np.sqrt(sigQnr_c_v(xl)**2+(Cms+slope*xl)**2), color=\"r\", lw=2, alpha=0.8)\n",
    "#pl.errorbar(x, y, yerr=yerr, fmt=\".k\")\n",
    "pl.xlim(10, 200)\n",
    "pl.ylim(0.03,0.12)\n",
    "pl.errorbar(E_recoil[2::], sig_NR[2::], yerr=sig_NR_err[2::], fmt=\".k\", capsize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampsize=100\n",
    "evec = np.zeros((np.shape(xl)[0],sampsize))\n",
    "#print(samples[np.random.randint(len(samples), size=sampsize)])\n",
    "i=0\n",
    "for Cms_em, m_em in samples[np.random.randint(len(samples), size=sampsize)]:\n",
    "    v = np.sqrt(sigQnr_c_v(xl)**2+(Cms_em+m_em*xl)**2)\n",
    "    #print(np.std(v))\n",
    "    #print(np.mean(v))\n",
    "    cent = np.sqrt(sigQnr_c_v(xl)**2+(Cms+slope*xl)**2)\n",
    "    evec[:,i] = v\n",
    "    #print(i)\n",
    "    #print(np.mean(v)+np.std(v))\n",
    "    #print(np.mean(v)-np.std(v))\n",
    "    i=i+1\n",
    "   \n",
    "upvec = np.mean(evec,axis=1)+np.std(evec,axis=1)\n",
    "dnvec = np.mean(evec,axis=1)-np.std(evec,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(xl, np.sqrt(sigQnr_c_v(xl)**2+(Cms+slope*xl)**2), color=\"r\", lw=2, alpha=0.8)\n",
    "pl.plot(xl, upvec, color=\"r\",linestyle=\"--\", lw=2, alpha=0.8)\n",
    "pl.plot(xl, dnvec, color=\"r\",linestyle=\"--\", lw=2, alpha=0.8)\n",
    "#pl.errorbar(x, y, yerr=yerr, fmt=\".k\")\n",
    "pl.xlim(10, 200)\n",
    "pl.ylim(0.03,0.12)\n",
    "#args=(E_recoil[2::], sig_NR[2::], sig_NR_err[2::],sigQnr_c_v))\n",
    "pl.errorbar(E_recoil[2::], sig_NR[2::], yerr=sig_NR_err[2::], fmt=\".k\", capsize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results for the MS fit\n",
    "path='{}/{}/'.format('mcmc','edwdata')\n",
    "\n",
    "filename = 'data/mcmc_fits.h5'\n",
    "\n",
    "#remove vars\n",
    "f = h5py.File(filename,'a')\n",
    "exCms = path+'Cms' in f\n",
    "exm = path+'m' in f\n",
    "exsamp = path+'samples' in f\n",
    "exsampsize = path+'sampsize' in f\n",
    "exEr = path+'Er' in f\n",
    "exCsig_u = path+'Csig_u' in f\n",
    "exCsig_l = path+'Csig_l' in f\n",
    "exSigss = path+'Sigss' in f\n",
    "\n",
    "if exCms:\n",
    "  del f[path+'Cms']\n",
    "if exm:\n",
    "  del f[path+'m']\n",
    "if exsamp:\n",
    "  del f[path+'samples']\n",
    "if exsampsize:\n",
    "  del f[path+'sampsize']\n",
    "if exEr:\n",
    "  del f[path+'Er']\n",
    "if exCsig_u:\n",
    "  del f[path+'Csig_u']\n",
    "if exCsig_l:\n",
    "  del f[path+'Csig_l']\n",
    "if exSigss:\n",
    "  del f[path+'Sigss']\n",
    "\n",
    "dset = f.create_dataset(path+'Cms',np.shape(Cms),dtype=np.dtype('float64').type)\n",
    "dset[...] = Cms\n",
    "dset = f.create_dataset(path+'m',np.shape(slope),dtype=np.dtype('float64').type)\n",
    "dset[...] = slope\n",
    "dset = f.create_dataset(path+'samples',np.shape(samples),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = samples\n",
    "dset = f.create_dataset(path+'sampsize',np.shape(sampsize),dtype=np.dtype('float64').type)\n",
    "dset[...] = sampsize\n",
    "dset = f.create_dataset(path+'Er',np.shape(xl),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\")\n",
    "dset[...] = xl\n",
    "dset = f.create_dataset(path+'Csig_u',np.shape(upvec),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = upvec\n",
    "dset = f.create_dataset(path+'Csig_l',np.shape(dnvec),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = dnvec\n",
    "dset = f.create_dataset(path+'Sigss',np.shape(xl),dtype=np.dtype('float64').type, \\\n",
    "compression=\"gzip\",compression_opts=9)\n",
    "dset[...] = sigQnr_c_v(xl)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py373_gammapi] *",
   "language": "python",
   "name": "conda-env-py373_gammapi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
